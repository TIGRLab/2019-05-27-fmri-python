{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Python Neuroimaging Workshop!\n",
    "\n",
    "- Welcome statement \n",
    "- What we'll cover\n",
    "- Goals of the workshop\n",
    "- \n",
    "\n",
    "Welcome to our Python Neuroimaging Analysis workshop. In this workshop we'll teach you the tools to perform reproducible analyses on functional neuroimaging (fMRI) data using Python and Jupyter notebooks. The focus of this workshop is to learn the basics of image manipulation and analysis using *already pre-processed data*; data pre-processing is a whole other topic that we'll briefly touch on. We'll start with a basic overview of how we can load, view, and play around with MR images using Python's neuroimaging libraries (<code>Nilearn</code>), then we'll eventually perform a full functional connectivity analysis in order to make inferences about whole-brain activity. \n",
    "\n",
    "### Why Python?\n",
    "\n",
    "Python is rapidly becoming the standard language for data analysis, visualization and automated workflow building. It is a free and open-source software that is relatively easy to pick up by new programmers. In addition with Python packages such as <code>Jupyter</code> one can keep an interactive code journal of analysis - this is what we'll be using in the workshop, and is, in fact, what you are currently using to view this workshop! Using Jupyter notebooks allows you to keep a record of all the steps in your analysis enabling transparency in analysis and ease of code sharing. \n",
    "\n",
    "Another advantage of Python is that it is maintained by a large user-base. Anyone can easily make their own Python packages for others to use, therefore there exists a *very* large codebase for you to take advantage of for your neuroimaging analysis; from basic statistical analysis to advanced machine learning and multivariate methods!\n",
    "\n",
    "We'll begin with a basic overview of MR data then move into how we can work with MR data in python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of MR Scans\n",
    "\n",
    "<img src=\"../static/images/mr_scan_types.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\">\n",
    "\n",
    "For this tutorial, we'll be focusing on T1w and resting state fMRI scans.\n",
    "\n",
    "### Neuroimaging File Formats\n",
    "\n",
    "|Format Name | File Extension | Origin |\n",
    "|---|---|---|\n",
    "| Analyze | .img/.hdr | Analyze Software, Mayo Clinic |\n",
    "| DICOM | none | ACR/NEMA Consortium |\n",
    "| NIfTI | .nii or .img/.hdr | Neuroimaging Informatics Technology Initiative |\n",
    "| MINC | .mnc | Montreal Neurological Institute |\n",
    "| NRRD | .nrrd | |\n",
    "\n",
    "<img src=\"../static/images/dicom_to_nifti.png\" alt=\"Drawing\" align=\"middle\" width=\"300px\"/>\n",
    "\n",
    "From the MRI scanner, images are initially collected in the DICOM format and can be converted to NIfTI using [dcm2niix](https://github.com/rordenlab/dcm2niix).\n",
    "\n",
    "### Intro to NIfTI\n",
    "\n",
    "NIfTI is one of the most ubiquitous file formats for storing neuroimaging data. We'll cover a few details to get started working with them. If you're interested in learning more about NIfTI images, we highly recommend [this blog post about the NIfTI format](http://brainder.org/2012/09/23/the-nifti-file-format/).\n",
    "\n",
    "***\n",
    "\n",
    "### Working with NIfTI packages in Python (Nilearn)\n",
    "\n",
    "[Nilearn](https://nilearn.github.io/) is a functional neuroimaging analysis and visualization library that wraps up a whole bunch of high-level operations (machine learning, statistical analysis, data cleaning, etc…) in easy-to-use commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "The first thing we’ll do is to important some Python modules that will allow us to use Nilearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerry/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "UsageError: unrecognized arguments: #for inline visualization in jupyter notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image as img\n",
    "from nilearn import plotting as plot\n",
    "%matplotlib inline #for inline visualization in jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we imported two things:\n",
    "\n",
    "1. <code> image as img </code> - allows us to load NIfTI images\n",
    "2. <code> plotting as plot </code> - allows us to use Nilearn's plotting library for easy visualization\n",
    "\n",
    "Let's grab an example scan to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-15de93695d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maffine\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \"\"\"\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwildcards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwildcards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/scwg_neuroimaging/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'"
     ]
    }
   ],
   "source": [
    "t1_img = img.load_img('../data/ds000030/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in a NIfTI file with <code>nilearn</code> gives us a special type of data object which encodes all the information available in the NIfTI file. To see all of these attributes, type `t1_img.` and <kbd>Tab</kbd>.  \n",
    "There are three main attributes that we'll discuss today:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [Header](http://nipy.org/nibabel/nibabel_images.html#the-image-header): contains metadata about the image, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr = t1_img.header\n",
    "print(t1_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>t1_img</code> image header is a [Python dictionary](https://www.w3schools.com/python/python_dictionaries.asp). Dictionaries are containers which can store a variety of information called **values** which can be accessed using a **key**. \n",
    "\n",
    "Similar to <code>t1_img</code> in which attributes can be accessed via typing <code>t1_img.</code> and hitting <kbd>Tab</kbd>, you can do the same with <code>t1_hdr</code>. In particular, we'll be using a *method* (a process) belonging to <code>t1_hdr</code> that will allow you to view the keys associated with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that *methods* include <code>()</code> at end whereas *attributes* do not. \n",
    "\n",
    "The key difference between a method and an attribute is:\n",
    "- Attributes are *stored values* kept within an object\n",
    "- Methods are *processes* that we can run using the object. Usually a method takes *attributes*, performs an operation on them, then returns it for you to use.\n",
    "\n",
    "You can view the *methods* and *attributes* of a particular object by typing:\n",
    "\n",
    "~~~python\n",
    "?t1_img\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is a list of **keys** you can use from <code>t1_hdr</code> to access **values**. \n",
    "\n",
    "We can access the value stored by a given key by typing:\n",
    "\n",
    "```python\n",
    "t1_hdr['<key_name>']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Extract the value of <code>pixdim</code> from <code>t1_hdr</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr['pixdim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MR Data\n",
    "As you've seen above, the header contains useful information that gives us information about the properties (metadata) associated with the MR data we've loaded in. Now we'll move in to loading the actual *image data itself*. We can achieve this by using the *method* called <code>t1_img.get_data()</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t1_img.get_data()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>t1_img.get_data()</code> returns an <code>array</code> object which contains 3 dimensions. You can think of <code>data</code> as a 3D version of a picture (more accurately, a volume):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../static/images/numpy_arrays.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 3D array contains a value for each (x,y,z) coordinate in our image. You can think of our <code>data</code> object as this 3D volume made up of cubes, and these cubes make up a \"picture\" of the MR scan as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sprawls.org/mripmt/MRI10/MR10-2.jpg\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect some *attributes* of this <code>data</code> object!\n",
    "\n",
    "First, let's get an idea about how big it is. The <code>.shape</code> attribute tells us this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 numbers given here represent the number of values *along a respective dimension (x,y,z)*. That means in total there are:\n",
    "\n",
    "$$x * y * z = value$$ voxels in total!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
